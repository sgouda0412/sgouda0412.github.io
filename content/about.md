+++
title = "ğŸ’» About Me: Senior Data Engineer"
description = "A Data Engineer loves buiding Data Pipelines"
date = "2025-03-27"
aliases = ["about-us","Data Engineer","Senior Data Engineer","Linux","contact"]
author = "Santosh Kumar Gouda"
+++

**Hello!** ğŸ‘‹  
I'm **Santosh Kumar Gouda**, a **Senior Data Engineer** with **8.5+ years** of experience architecting cloud-native data solutions. I transform complex data challenges into scalable, cost-efficient systemsâ€”proven by **40%+ performance gains** across multiple enterprises.

---

## ğŸ› ï¸ **Technical Arsenal**

### **ğŸ§° Core Stack**
| **Category**       | **Technologies**                                                                 |
|--------------------|---------------------------------------------------------------------------------|
| **Cloud Platforms**| AWS (Glue, Redshift, S3, EMR, Lambda, RDS, ), Azure (Data Factory, Databricks, Synapse) |
| **Big Data**       | PySpark, Airflow, Kafka, Snowflake, Delta Lake                                 |
| **Databases**      | PostgreSQL, MySQL, MongoDB, Azure SQL, Redshift                                |
| **DataOps**        | dbt, Great Expectations,, Kubernetes, Docker, CI/CD                                      |

---

## ğŸ’¼ **Professional Journey**

### **ğŸš€ Data Analytic Tech Lead**  
ğŸ“ **Sears Global Technologies** | Nov 2022 - Present | *Pune*  
- Engineered **Snowflake ingestion pipelines** from OLTP systems (MySQL/PostgreSQL/MongoDB) and **S3/SFTP**, achieving **30% faster data delivery**  
- Automated **200+ ETL workflows** using **Apache Airflow**, reducing manual intervention by **40%** with **99% on-time delivery**  
- Designed **complex SQL queries** for ad-hoc analytics, maintaining **98% stakeholder satisfaction**  
- Implemented **data quality frameworks** that reduced pipeline failures by **35%**

### **ğŸ”§ Data Engineer**  
ğŸ“ **Enkash** | May 2022 - Sep 2022 | *Bangalore*  
- Built **AWS Glue/PySpark pipelines** to migrate on-prem MySQL â†’ **Redshift**, cutting processing time by **40%**  
- Developed **advanced Glue scripts** optimizing transformation logic, reducing job runtime by **25%**  
- Created **interactive QuickSight dashboards** serving **200+ business users** with real-time sales insights  

### **ğŸ”§ Data Engineer**  
ğŸ“ **Tech Mahindra** | May 2021 - May 2022 | *Bangalore*  
- Consolidated **1TB+ disparate data sources** using **AWS Glue/S3**, enabling unified analytics  
- Automated **data reconciliation** with Python, achieving **90% accuracy improvement** and saving **20+ hours/week**  
- Enhanced **ETL performance** reducing data wrangling time by **40%**  

### **ğŸ”§ Data Engineer**  
ğŸ“ **Alten India** | Sep 2020 - Apr 2021 | *Bangalore*  
- Migrated **legacy SSIS packages** â†’ **Azure Databricks**, slashing ETL runtime by **35%**  
- Developed **Azure Data Factory pipelines** integrating Blob Storage â†’ Data Warehouse, boosting efficiency by **50%**  

### **ğŸ”§ Data Analytics Engineer**  
ğŸ“ **Bristlecone** | Nov 2019 - Sep 2020 | *Bangalore*  
- Architected **data management framework** reducing retrieval time by **25%**  
- Processed **500K+ records/day** into Azure Data Lakes, improving accessibility by **30%**  

### **ğŸ”§ Data Analyst**  
ğŸ“ **Accenture Solutions** | Jan 2016 - Sep 2018 | *Bangalore*  
- Automated data extraction with Python, cutting acquisition time by **35%**  
- Resolved **50+ critical script errors**, ensuring system stability  

---

## ğŸ—ï¸ **Signature Projects**

### **ğŸ”— Real-Time Payment Analytics**  
*Tech: Kafka â€¢ PySpark â€¢ Redshift â€¢ Airflow*  
- Processed **2M+ transactions/day** with <100ms latency  
- Reduced fraud detection time from **hours â†’ seconds**  

### **ğŸ”— Cloud Data Migration **  
*Tech: Python â€¢ PySpark â€¢ SQL â€¢ Airflow â€¢ AWS Glue â€¢ Snowflake*  
- Cut **ETL costs by 40%** via auto-scaling and partitioning  
- Documented as **internal gold standard**  

---

## ğŸ“š **Blog Posts & Writing**
- **[Handling Large Data Volumes (100GB â€” 1TB) in PySpark: Best Practices & Optimizations](https://medium.com/@sgouda835/handling-large-data-volumes-100gb-1tb-in-pyspark-best-practices-optimizations-b0ce2fe73f24)**  
  *(Practical handling of big data and  optimization strategies for data warehouses)*  
- **[ Data Engineering Best Practices for Production Data Pipelines](https://medium.com/@sgouda835/data-engineering-best-practices-for-production-data-pipelines-1b9fdc5df863)**  
  *(Best Practices of Data Pipelines)*  


---
## ğŸ“š **Knowledge Leadership**
- **ğŸ† Certifications**:  
  - Microsoft Certified **Azure Data Engineer Associate** (2025)  
  - AWS Certified **Data Analytics Specialty** (2025)  
- **ğŸ“ Education**: B.Tech in CSE @ NIT Nagaland (7.74 CGPA)  

---

## ğŸ“„ **Resume**  
[ğŸ“„ Download Resume](https://github.com/sgouda0412/Resume/raw/main/SantoshKumarGouda_DataEngineer_8.5%2ByrsExp_Resume.pdf) | 
[ğŸ‘€ View Online](https://drive.google.com/file/d/185aeLXNn5r86joCJ4hETu7pe959hHjQd/view?usp=sharing)

---

## ğŸŒŸ **Beyond Code**
- ğŸ§  Mentor for early-career data professionals  
- ğŸ“š Contributor to open-source data tools  

---

## ğŸ“« **Let's Build Something Great**  

| **Platform**  | **Link**                          |
|--------------|-----------------------------------|
| **Email**    | s.k.gouda21@gmail.com             |
| **LinkedIn** | [linkedin.com/in/sgouda0412]     |
| **GitHub**   | [github.com/sgouda0412]         |
| **Phone**    | +91-7619264934                    |

**Open to:**  
- Architectural consultations  
- High-impact data engineering projects  
- Speaking/mentorship opportunities  

> *"Data systems should scale like bambooâ€”strong, flexible, and resilient."* ğŸ  

